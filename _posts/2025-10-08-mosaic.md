---
layout: post
title: "Generating Image Mosaics (and more!)"
published: true
---

# Introduction
This is my third project for CS 180 (Intro to Computer Vision) at UC Berkeley.
The project covers image warping, image mosaic generation, and corner detection algorithms (to be added to this page soon!)

# Part A.1: Shoot the Pictures
The first part of the assignment is to show at least 2 sets of images with projective transformations between them (fixed center of projection, rotate camera).
The reason we are doing this is because we can then use these images to construct mosaics later on in the assignment.

**Set 1:**
<p align="center">
  <img src="/assets/images/mosaic/input/northside1.jpg" width="500"/>
</p>

<p align="center">
  <img src="/assets/images/mosaic/input/northside2.jpg" width="500"/>
</p>

**Set 2:**
<p align="center">
  <img src="/assets/images/mosaic/input/library1.jpg" width="500"/>
</p>
<p align="center">
  <img src="/assets/images/mosaic/input/library2.jpg" width="500"/>
</p>

Notice how the camera *position* is the same in both sets of images; all we're doing is rotating it.
Eventually, we will stich these images together to create an *image mosaic* (see part A.4!).

# Part A.2: Recover Homographies

A **homography** is a 3×3 projective transformation that maps points from one image to another when both images capture the same planar scene.  

For this exercise, consider the below two images:

<p align="center">
  <img src="/assets/images/mosaic/output/library_compare.jpeg" width="500"/>
</p>

Observe that I manually selected **correspondence points** between the two images.
These are necessary to align the images properly.
Only four points are strictly necessary for the algorithm to work, but in practice it makes sense to select many more than four for redundancy.

In homogeneous coordinates: `p2 = Hp1`, 
where `p1 = [x, y, 1]^T`, `p2 = [x', y', w']^T`, and `H` is:

```
[ h11 h12 h13
h21 h22 h23
h31 h32 h33 ]
```

We convert the system to Cartesian coordinates by dividing by the 'scaling factor' introduced by the Homogeneous coordinates:

```
x' = (h11*x + h12*y + h13) / (h31*x + h32*y + h33)
y' = (h21*x + h22*y + h23) / (h31*x + h32*y + h33)
```
Rearranging gives two equations per correspondence:
```
x*h11 + y*h12 + 1*h13 - x*x'*h31 - y*x'*h32 = x'*h33
x*h21 + y*h22 + 1*h23 - x*y'*h31 - y*y'*h32 = y'*h33
```

Setting `h33` to 1 as discussed in class, **we arrive at the system of equations:**

```
x' = x*h11 + y*h12 + 1*h13 - x*x'*h31 - y*x'*h32 
y' = x*h21 + y*h22 + 1*h23 - x*y'*h31 - y*y'*h32 
```

Stacking all pairs yields the linear system `Ah = b` with  
`h = [h11 h12 h13 h21 h22 h23 h31 h32]^T`.
I solved the resulting system of equations using least-squares (because we have >4 correspondences, the system is overdetermined).

This is the **homography matrix H** which I recovered:
```
[[ 1.46568340e+00 -1.20053461e-01 -4.98410322e+02]
[ 2.29064746e-01  1.24290079e+00 -1.30462059e+02]
[ 5.01352998e-04 -9.85491138e-05  1.00000000e+00]]
```

# Part A.3: Image Warping and Rectification

In this section, I use the recovered homography **H** to warp images toward a reference view using **inverse warping**.  
Inverse warping maps each pixel in the *output* image back into the *input* image coordinate system.
This prevents holes or "gaps" in the outputted image.

---

## 1) Warp Functions
After we inverse-warp the image, there's a problem: the resulting coordinate values are not integers!
There are many kinds of interpolation methods we can apply to address this problem.
Here I discussed two interpolation methods that I implemented from scratch.

**Nearest Neighbor Interpolation**: Round coordinates to the nearest pixel value. Runs relatively quickly but the results aren't as good as bilinear interpolation.
**Bilinear Neighbor Interpolation**: Use a weighted average of four neighboring pixels. Takes longer but gives better-quality results.

## 2) Results
In the below image, zoom in on the words "vegetarian" and "vegan" on the sign. 
Notice how the bordering around the letters is less jagged and pixelated in the bilinear interpolation image, compared to nearest-neighbor.

<p align="center">
  <img src="/assets/images/mosaic/output/sign_rectification.png" width="800"/>
</p>

Here's another example:

<p align="center">
  <img src="/assets/images/mosaic/output/campanile_rectification.png" width="800"/>
</p>

For these examples, there is no ''second image'': instead, we warp the first image to a predetermined shape (a rectangle).

For the campanile example, I set the second image's coordinates to that of a rectangle with height four times that of the width. Here's what the coordinates of that rectangle looked like, for reference:
```
  "im2Points": [
    [0, 0],
    [1, 0],
    [1, 4],
    [0, 4]
  ]
```

For the sign image, I used a rectangle with height 1.58 times the width.
I determined these values through manual measurement of the image and trial and error.

# Part A.4 Blend the Images into a Mosaic

In this next part, I developed an algorithm to stich images together into panoramas!

## Procedure (one-shot, inverse warping)

1. **Choose reference:**
   Leave one image unwarped and warp the other into its projection using the computed homography.

2. **Create alpha masks:**
   For each warped image, define an **alpha mask** that marks which pixels contain valid image data after warping.

   * Pixels that were filled during warping are set to `1` (valid).
   * Empty or outside regions remain `0`.
     These masks later help identify which parts of the canvas belong to which image and guide blending in overlapping areas.

3. **Apply weighted averaging to reduce artifacts:**
   To smooth the overlap between the two images, I gave each pixel a weight based on how far it is from the image edge.
   To accomplish this, I define variables `weight_1` and `weight_2`, where each is computed from the **distance transform** of its image’s alpha mask:
   ```
   dist_1 = distance_transform_edt(alpha_mask_1) # distance transform method imported from scipy
   weight_1 = dist_1 / (np.max(dist_1) + 1e-8)
   # dist_2, weight_2 defined the same way
   ```

   Pixels near the center of each image have higher weights, and edge pixels have lower weights.
   When blending, areas of overlap are averaged accordingly:
   ```
   mosaic = (weight_1 * image_1 + weight_2 * image_2) / (weight_1 + weight_2)
   ```

   This produces a soft, seamless transition between the two images.
   (In practice, the averaging is applied separately to each color channel, not all at once.)


## Results

Here are the mosaics with the original images:
<p align="center">
  <img src="/assets/images/mosaic/output/road1_road2_mosaic_compare.png" width="800"/>
</p>

<p align="center">
  <img src="/assets/images/mosaic/output/northside1_northside2_mosaic_compare.png" width="800"/>
</p>

<p align="center">
  <img src="/assets/images/mosaic/output/library1_library2_mosaic_compare.png" width="800"/>
</p>

Here are the mosaics on their own for reference:

<p align="center">
  <img src="/assets/images/mosaic/output/road1_road2_mosaic.png" width="600"/>
</p>

<p align="center">
  <img src="/assets/images/mosaic/output/northside1_northside2_mosaic.png" width="600"/>
</p>

<p align="center">
  <img src="/assets/images/mosaic/output/library1_library2_mosaic.png" width="600"/>
</p>
