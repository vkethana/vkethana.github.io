<!DOCTYPE html>
<html lang="en" data-theme="dark-poole">

  <head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<title>
	vkethana
</title>

<link rel="stylesheet" href="/assets/css/styles.css" />
<link rel="shortcut icon" href="/dark-poole/assets/favicon.ico" />
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ChatGPT is not a next-word predictor | vkethana</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="ChatGPT is not a next-word predictor" />
<meta name="author" content="Vijay Kethanaboyina" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="When ChatGPT first came out around a year ago, I remember that my 12th AP government instructor had us discuss it in class. The consensus was that ChatGPT can’t understand anything, because it simply predicts whatever word is most statistically likely to appear next in a sentence. LLMs remix and compress their training data, and they cannot “think.”" />
<meta property="og:description" content="When ChatGPT first came out around a year ago, I remember that my 12th AP government instructor had us discuss it in class. The consensus was that ChatGPT can’t understand anything, because it simply predicts whatever word is most statistically likely to appear next in a sentence. LLMs remix and compress their training data, and they cannot “think.”" />
<link rel="canonical" href="http://localhost:4000/chatgpt/" />
<meta property="og:url" content="http://localhost:4000/chatgpt/" />
<meta property="og:site_name" content="vkethana" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-03-25T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ChatGPT is not a next-word predictor" />
<meta name="twitter:site" content="@v_kethana" />
<meta name="twitter:creator" content="@Vijay Kethanaboyina" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Vijay Kethanaboyina","url":"https://vkethana.com"},"dateModified":"2024-03-25T00:00:00-07:00","datePublished":"2024-03-25T00:00:00-07:00","description":"When ChatGPT first came out around a year ago, I remember that my 12th AP government instructor had us discuss it in class. The consensus was that ChatGPT can’t understand anything, because it simply predicts whatever word is most statistically likely to appear next in a sentence. LLMs remix and compress their training data, and they cannot “think.”","headline":"ChatGPT is not a next-word predictor","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/chatgpt/"},"url":"http://localhost:4000/chatgpt/"}</script>
<!-- End Jekyll SEO tag -->


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DHP8MNS84G"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DHP8MNS84G');
</script>

</head>


  <body>
    <div class="container content">
      <header class="masthead">
	<h3 class="masthead-title">
		<a href="/" title="Home">vkethana.com</a>
		<nav class="nav">
			<small><a href="/writings">Writings</a></small>
			<small><a href="/reading_log">Reading Log</a></small>
		</nav>
	</h3>
</header>


      <main>
        <h1 class='post-title'>ChatGPT is not a next-word predictor</h1>
<time datetime="2024-03-25T00:00:00-07:00" class="post-date">25 Mar 2024</time>
<hr />
<p>When ChatGPT first came out around a year ago, I remember that my 12th AP government instructor had us discuss it in class. The consensus was that ChatGPT can’t understand anything, because it simply predicts whatever word is most statistically likely to appear next in a sentence. LLMs remix and compress their training data, and they cannot “think.”</p>

<p>This didn’t sound right to me, but at the time I didn’t know much about how LLMs works. But as the months went by, I heard this same idea repeated over and over – that these models are simply a more advanced version of the “predictive text” feature you see when typing on a cell phone. 
Here’s why I think it’s wrong.</p>

<h2 id="it-cant-be-that-simple">It can’t be that simple</h2>
<p>If ChatGPT were nothing more than “next-word prediction”, then why wasn’t it made decades ago?
After all, the necessary hardware (fancy GPUs) and training data (the internet) have been around for years. 
It is true that GPUs have gotten a lot better in the past few years, but that doesn’t matter here. 
Suppose that someone in 2015 had come up with a simplified form of GPT-3 using the much-worse hardware available at the time. 
Even if it took 5 minutes to receive an answer instead of 5 seconds, it still would’ve been the best product out there by 2015 standards.</p>

<p><a href="The">The</a> reason why ChatGPT couldn’t have been invented 10 years ago isn’t just because of better hardware or training data. 
What really happened is that there was a breakthrough	in model architectures, which started when a team of Google researchers published <em>Attention is All You Need</em> in 2017.</p>

<figure>
  <img src="/assets/images/transformer.webp" alt="the Transformer architecture" class="center" />
  <figcaption>Fig. 1: The Transformer Architecture</figcaption>
</figure>
<p><br /></p>

<p>Clearly, the transformer architecture took a lot of tinkering and ingenuity to come up with: it required creativity. Saying that LLMs are simply regurgitators of training data implicitly denies that this creativity ever existed, and it downplays the role that key researchers, e.g. the authors of <em>Attention is All You Need</em>, played in bringing about these advancements.</p>

<h2 id="things-are-still-fuzzy">Things are still fuzzy</h2>
<p>The truth is that nobody (not even Sam Altman!) really understands how LLMs work. If this is true, then how was this stuff invented in the first place?</p>

<p>The answer is that you don’t need to know <em>why</em> something works in order to know <em>how</em> it works. For example, the Wright Brothers flew at Kitty Hawk way before Aerospace Engineering was a formal discipline. The theory behind why airplanes work didn’t come until much later.
Similarly, nobody right now really understands why the transformer architecture works. To quote Stephen Wolfram’s <em>What Is ChatGPT Doing … and Why Does It Work?</em>, “this is just one of those things that’s been ‘found to work.’”
I think Wolfram is right: right now AI is in a “tinkering” stage. As a result, we have things like prompt engineering, feedback loops supported by human trainers, tweaking architectures to see how the model’s performance changes. Once the dust settles, AI will evolve into a theoretical disclipline.</p>

<h2 id="bonus-word-regurgitators-are-nothing-new">Bonus: word-regurgitators are nothing new</h2>
<p>Now for some interesting computational linguistics trivia: word-regurgitating algorithms actually have existed for a while. One good example is the invention of the “context-free grammar” in the 1970s. Here’s a sample sentence from SCIGen, a program that uses a context-free grammar to generate seemingly-coherent computer science research papers. In reality, the papers are completely full of nonsense:</p>
<blockquote>
  <p>“We consider an algorithm consisting of n semaphores.
Any unproven synthesis of introspective methodologies will
clearly require that the well-known reliable algorithm for the
investigation of randomized algorithms by Zheng is in Co-NP;
our application is no different. The question is, will Rooter
satisfy all of these assumptions? No.” <sup id="fnref:fn-1" role="doc-noteref"><a href="#fn:fn-1" class="footnote" rel="footnote">1</a></sup></p>
</blockquote>

<p>In short, we give ChatGPT some credit: at the very least, it’s miles ahead of SCIGen.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:fn-1" role="doc-endnote">
      <p>Fun fact: <a href="https://pdos.csail.mit.edu/archive/scigen/">this paper</a> was actually accepted as a “non-reviewed paper” to the World Multiconference on Systemics, Cybernetics and Informatics in 2005. <a href="#fnref:fn-1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>


      </main>

      <footer class="footer">
        <small>
          &copy;
          <time datetime="2024"
            >2024</time
          > Vijay Kiran Kethanaboyina. All rights reserved.
        </small>
      </footer>
      </div>
  </body>
</html>

